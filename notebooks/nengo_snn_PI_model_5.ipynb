{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-trick",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tables\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.fftpack import idst, dst\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "import datetime\n",
    "from utils import *\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constitutional-leader",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nengo_dl\n",
    "import nengo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-cincinnati",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fftpack import idst,dst\n",
    "type = 2\n",
    "def denom_matrix(n_row,n_col):\n",
    "    x = np.linspace(1, n_col, n_col)\n",
    "    y = np.linspace(1, n_row,n_row)\n",
    "    xv, yv = np.meshgrid(x, y)\n",
    "\n",
    "    return np.transpose(((2*np.cos(np.pi*xv/(n_col+1))-2) + (2*np.cos(np.pi*yv/(n_row+1)) - 2)).flatten()) \n",
    "\n",
    "def DST_matrix(h,w,dim ='row'): \n",
    "    if(dim == 'row'):\n",
    "        d = dst(np.eye(h), axis=0,type = type)\n",
    "        return np.kron(np.eye(w),d)\n",
    "    else:\n",
    "        d = dst(np.eye(w), axis=0,type = type)\n",
    "        return np.kron(np.eye(h),d)   \n",
    "\n",
    "def IDST_matrix(h,w,dim ='row'): \n",
    "    if(dim == 'row'): \n",
    "        d = idst(np.eye(h), axis=0,type = type)\n",
    "        return np.kron(np.eye(w),d)\n",
    "    else:\n",
    "        d = idst(np.eye(w), axis=0,type = type)\n",
    "        return np.kron(np.eye(h),d)\n",
    "\n",
    "def DFT_matrix(N):\n",
    "    i, j = np.meshgrid(np.arange(N), np.arange(N))\n",
    "    omega = np.exp( - 2 * np.pi * 1J / N )\n",
    "    W = np.power( omega, i * j ) / np.sqrt(N)\n",
    "    return W \n",
    "\n",
    "def transform_2d(n_row,n_col):\n",
    "    n = np.arange(0,n_row*n_col)\n",
    "    \n",
    "    w = np.zeros((n_row*n_col,n_row*n_col))\n",
    "    n1 = np.transpose(np.reshape(n,(n_row,n_col))).flatten()\n",
    "    j = 0\n",
    "    for i in n1:        \n",
    "        w[i,j] = 1\n",
    "        j = j+1\n",
    "    return w.T \n",
    "\n",
    "\n",
    "\n",
    "def DST_matrix_s(h,w,dim ='row'): \n",
    "    if(dim == 'row'):\n",
    "        d = dst(np.eye(h), axis=0,type = type)\n",
    "        return scipy.sparse.kron(scipy.sparse.eye(w),d)\n",
    "        \n",
    "    else:\n",
    "        d = dst(np.eye(w), axis=0,type = type)\n",
    "        return scipy.sparse.kron(scipy.sparse.eye(h),d)\n",
    "        \n",
    "def IDST_matrix_s(h,w,dim ='row'): \n",
    "    if(dim == 'row'): \n",
    "        d = idst(np.eye(h), axis=0,type = type)\n",
    "        return scipy.sparse.kron(scipy.sparse.eye(w),d)\n",
    "        \n",
    "    else:\n",
    "        d = idst(np.eye(w), axis=0,type = type)\n",
    "        return scipy.sparse.kron(scipy.sparse.eye(h),d)\n",
    "        \n",
    "\n",
    "def create_weights(h,w):\n",
    "    tr_2d = transform_2d(h,w)\n",
    "    w_dst_r = DST_matrix_s(h,w)\n",
    "    w_dst_c = DST_matrix_s(h,w,dim='col')\n",
    "    w_idst_r = IDST_matrix_s(h,w)\n",
    "    w_idst_c = IDST_matrix_s(h,w,dim='col')\n",
    "    w_dem = denom_matrix(h,w) \n",
    "    W =  tr_2d.T @ w_idst_r @ tr_2d @ w_idst_c @ np.diag((1/w_dem)) @ tr_2d.T @ w_dst_r @ tr_2d @ w_dst_c\n",
    "    del tr_2d,w_dst_r,w_dst_c,w_idst_c,w_idst_r,w_dem \n",
    "    W = W - np.min(W)\n",
    "    W = W/np.max(W)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-eagle",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = tf.keras.Input(shape=(90, 120, 6))\n",
    "\n",
    "# convolutional layers\n",
    "\n",
    "conv0 = tf.keras.layers.Conv2D(\n",
    "    filters=3,\n",
    "    kernel_size=3,\n",
    "    padding='same',\n",
    "    activation=tf.nn.relu,\n",
    ")(inp)\n",
    "\n",
    "conv1 = tf.keras.layers.Conv2D(\n",
    "    filters=3,\n",
    "    kernel_size=3,\n",
    "    padding='same',\n",
    "    activation=tf.nn.relu,\n",
    ")(conv0)\n",
    "\n",
    "conv2 = tf.keras.layers.Conv2D(\n",
    "    filters=3,\n",
    "    kernel_size=1,\n",
    "    padding='same',\n",
    "    activation=tf.nn.relu,\n",
    ")(conv1)\n",
    "\n",
    "conv3 = tf.keras.layers.Conv2D(\n",
    "    filters=3,\n",
    "    kernel_size=1,\n",
    "    padding='same',\n",
    "    activation=tf.nn.relu,\n",
    ")(conv2)\n",
    "\n",
    "conv4 = tf.keras.layers.Conv2D(\n",
    "    filters=1,\n",
    "    kernel_size=1,\n",
    "    padding='same',\n",
    "\n",
    ")(conv3)\n",
    "\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=inp, outputs=conv4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-airplane",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights\n",
    "model.load_weights(\"./traind_models/best_model_simple_6_fixed_model5.h5\")\n",
    "model.build((None, 90, 120, 6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modular-scope",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data\n",
    "y = np.load('./data/testy.npy')\n",
    "X = np.load('./data/testX.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-helena",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "valid_images = X.reshape((X.shape[0],1, -1))\n",
    "valid_labels = y.reshape((y.shape[0],1,-1))\n",
    "print(valid_images.shape)\n",
    "print(valid_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-microphone",
   "metadata": {},
   "outputs": [],
   "source": [
    "h,w = (90,120)\n",
    "W = create_weights(h,w)\n",
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-stupid",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n = h*w\n",
    "n_neurons_ens = 10\n",
    "\n",
    "\n",
    "\n",
    "def filling_in_network():\n",
    "    \n",
    "    with nengo.Network() as net:\n",
    "\n",
    "          net.input = nengo.Node(size_in=n)\n",
    "            \n",
    "\n",
    "          layer = nengo.networks.EnsembleArray(n_neurons_ens, n,\n",
    "                                                  neuron_type= nengo.SpikingRectifiedLinear()\n",
    "                                                  )\n",
    "\n",
    "\n",
    "          net.output = nengo.networks.EnsembleArray(n_neurons_ens, n,\n",
    "                                                  neuron_type= nengo.SpikingRectifiedLinear()\n",
    "                                                  )\n",
    "\n",
    "          nengo.Connection(net.input,layer.input)\n",
    "\n",
    "          nengo.Connection(layer.output,net.output.output,transform=(1-W))\n",
    "     \n",
    "\n",
    "\n",
    "    return net\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-compromise",
   "metadata": {},
   "outputs": [],
   "source": [
    "present_time = 0.1\n",
    "nengo_converter = nengo_dl.Converter(\n",
    "        model,\n",
    "        swap_activations={tf.nn.relu: nengo.SpikingRectifiedLinear()},\n",
    "        scale_firing_rates=100,\n",
    "        synapse=0.01,\n",
    "    )\n",
    "\n",
    "with nengo_dl.Simulator(nengo_converter.net) as nengo_sim:\n",
    "    nengo_sim.save_params('./save_model/keras_to_snn_params_caltech_albert_small')\n",
    "    nengo_sim.load_params('./save_model/keras_to_snn_params_caltech_albert_small')\n",
    "    nengo_sim.freeze_params(nengo_converter.net)\n",
    "print(nengo_converter.net.n_neurons)\n",
    "\n",
    "with nengo_converter.net:\n",
    "  \n",
    "    nengo_converter.inputs[inp].output = nengo.processes.PresentInput(\n",
    "      valid_images, presentation_time=present_time\n",
    "  )\n",
    "\n",
    "  \n",
    "    nengo_converter.net.output = nengo_converter.layers[conv4]\n",
    "\n",
    "\n",
    "with nengo_converter.net:\n",
    "    \n",
    "  # add in the inverter network\n",
    "    filling_in = filling_in_network()\n",
    "  \n",
    "  # make the connection from the output of the converter network to the input\n",
    "  # of the inverter network\n",
    "    nengo.Connection(nengo_converter.net.output, filling_in.input,transform = -8)\n",
    "\n",
    "  # add probes for demonstration purposes\n",
    "    convert_out_probe = nengo.Probe(nengo_converter.net.output, synapse=0.01)\n",
    "    filling_in_out_probe = nengo.Probe(filling_in.output.output, synapse=0.01)\n",
    "print(nengo_converter.net.n_neurons)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-evanescence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nengo_ocl\n",
    "runtime = 20 * present_time\n",
    "#with nengo_ocl.Simulator(nengo_converter.net) as sim:\n",
    "with nengo.Simulator(nengo_converter.net) as sim:\n",
    "    sim.run(runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binding-pound",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.data[filling_in_out_probe].shape\n",
    "plt.imshow(np.reshape(sim.data[filling_in_out_probe][199],(h,w)),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-sandwich",
   "metadata": {},
   "outputs": [],
   "source": [
    "#100\n",
    "from matplotlib.animation import ArtistAnimation\n",
    "from IPython.display import HTML\n",
    "fig = plt.figure()\n",
    "imgs = []\n",
    "for i in range(20*100):\n",
    "    \n",
    "    img = plt.imshow(np.reshape(sim.data[filling_in_out_probe][i],(h,w)), animated=True,cmap='gray')\n",
    "    \n",
    "    imgs.append([img])\n",
    "\n",
    "ani = ArtistAnimation(fig, imgs, interval=50, blit=True)\n",
    "HTML(ani.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rotary-speaker",
   "metadata": {},
   "outputs": [],
   "source": [
    "ani.save('result_model5_90_120.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-andrew",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_poisson(img_grad,isShow=False):\n",
    "    type = 2\n",
    "    if(len(img_grad.shape) == 3):\n",
    "        x = img_grad[:,:,0]\n",
    "    else:\n",
    "        x = img_grad    \n",
    "    h,w = x.shape\n",
    "    w_dem = denom_matrix(h,w)    \n",
    "    \n",
    "    z = dst(dst(x,type=type,axis=0).T,type=type,axis=0).T\n",
    "    d = np.reshape((1/(w_dem)),(h,w)) *  (z)\n",
    "    p = idst(idst(d,type=type,axis=0).T,type=type,axis=0).T\n",
    "    if isShow:\n",
    "        plt.imshow(np.reshape(p,(h,w)),cmap='gray')\n",
    "        plt.show()\n",
    "    return p\n",
    "\n",
    "def norm_image(img):\n",
    "    img = img-np.min(img)\n",
    "    return img/np.max(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-choice",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.mnightly-2021-02-02-debian-10-test",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:mnightly-2021-02-02-debian-10-test"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}